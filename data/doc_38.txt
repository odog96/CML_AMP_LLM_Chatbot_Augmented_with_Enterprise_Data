page 14, 2021.136 Noam Wies, Yoav Levine, and Amnon Shashua. The Learnability of InContext Learning, March 2023. arXiv2303.07895 cs. URL httparxiv.orgabs2303.07895, doi10.48550arXiv.2303.07895.137 Avi Wigderson. Mathematics and computation A theory revolutionizingtechnology and science. Princeton University Press, 2019.138 Wikipedia.URL httpsen.wikipedia.orgwikiReflectiveprogramming.139 Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. AnExplanation of Incontext Learning as Implicit Bayesian Inference, July2022. arXiv2111.02080 cs. URL httparxiv.orgabs2111.02080,doi10.48550arXiv.2111.02080.140 Greg Yang, Edward J. Hu, Igor Babuschkin, Szymon Sidor, XiaodongLiu, David Farhi, Nick Ryder, Jakub Pachocki, Weizhu Chen, and Jianfeng Gao. Tensor Programs V Tuning Large Neural Networks via ZeroarXiv2203.03466 condShot Hyperparameter Transfer, March 2022.mat. URL httparxiv.orgabs2203.03466, doi10.48550arXiv.2203.03466.141 Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths,Yuan Cao, and Karthik Narasimhan. Tree of Thoughts Deliberate Problem Solving with Large Language Models, May 2023. arXiv2305.10601cs. URL httparxiv.orgabs2305.10601, doi10.48550arXiv.2305.10601.142 Yuhui Zhang, Michihiro Yasunaga, Zhengping Zhou, Jeff Z. HaoChen,James Zou, Percy Liang, and Serena Yeung. Beyond Positive ScalingHow Negation Impacts Scaling Trends of Language Models, May 2023.arXiv2305.17311 cs. URL httparxiv.orgabs2305.17311, doi10.48550arXiv.2305.17311.143 Haoyu Zhao, Abhishek Panigrahi, Rong Ge, and Sanjeev Arora. DoTransformers Parse while Predicting the Masked Word?, March 2023.arXiv2303.08117 cs. URL httparxiv.orgabs2303.08117, doi10.48550arXiv.2303.08117.144 Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. MiniF2F a crosssystem benchmark for formal Olympiadlevel mathematics, February2022. arXiv2109.00110 cs. URL httparxiv.orgabs2109.00110,doi10.48550arXiv.2109.00110.46