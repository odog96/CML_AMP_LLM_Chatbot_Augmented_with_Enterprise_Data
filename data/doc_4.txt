use GPUs? Then those should be added to the OCP cluster as well. Other considerations include Persistent Volume (PV) storage = 4TB per ML Workspace. NFS storage (1 TB per workspace). See more on hardware requiremnets for CML. Assuming that this is a POC and you are going to install ECS and just CML. You can have 600GB block storage + 1000 GB NFS storage (Block if internal and NFS if external). RAID is not required and the disks can be HDD. https://docs.cloudera.com/cdp-private-cloud-data-services/1.4.0/installation-ecs/topics/cdppvc-installation-standalone-cml-requirements.html How does CML work with GPUs on OCP? Answer: There are additional steps required to make GPUs available to the OpenShift cluster. Public blog post from Cisco, including a video of the impact of the solution. Embedded Compute Service (ECS) How do we size hardware for CML on ECS? Answer: Memory and CPU requirements would be same as in How do we size hardware for CML on OCP? If only CML will be deployed on the cluster (e.g. for DataViz only), you can have 600GB block storage + 1000 GB NFS storage (Block if internal and NFS if external). RAID is not required and the disks can be HDD. https://docs.cloudera.com/cdp-private-cloud-data-services/1.4.0/installation-ecs/topics/cdppvc-installation-standalone-cml-requirements.html For production deployment external NFS is recommended (reference) Setting constant subdomain for ML Workspace? Answer: As of Data Services 1.5.0, it is possible to set ML workspace static subdomain at creation time. Previously this was randomly generated. This helps with knowing which wildcard certificate enterprise security will provide. CML on Public Cloud General How to size public cloud CML workspace? Answer: As always, sizing of ML workspace depends on the workloads that are expected to run on it. An extensive article Sizing CML Workspaces was written on sizing by Paul de Fusco. Can Ray or Dask distributed framework be used in CML? Answer: Yes to both. See Ray example here and for Dask we have an AMP. If you want to get up to speed quickly on difference between the two frameworks, have a read here. Also this Linked article on CML and Ray by Chris Van Dyke. A couple of Ray projects as well: Python Library to provision Ray in CML https://github.com/cloudera/cmlextras Starter Project AMP for Ray https://github.com/cpv0310/Ray-Starter How does suspend/resume work for ML Workspaces? Answer: Suspend/resume is currently tech preview (TP) on AWS and Azure. Both UI commands and CDP CLI commands are available. To get access to this feature, customer needs to have an entitlement (see ML_SUSPENDABLE). Instructions on how to do suspend and resume are pretty basic. Reference DSE-21659. Recording of a demo [passcode: 6c=h7gG. ] Resume and suspend operations take approximately 15 minutes each. When workspace is suspended, it will no longer be accessible to anyone and there will be no compute instances used for it (no CPU workers, no GPU workers), nor CML Infra nodes. However, the Lifty Platform node will continue to be up and running (no Cloudera charge for that). The volumes that EC2 instances were using will become detached (caution if customer has automatic GC scripts for this).