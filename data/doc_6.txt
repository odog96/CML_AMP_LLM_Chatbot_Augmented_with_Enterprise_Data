As we write this thestate of the art GPT4 demonstrates truly remarkable performance at questionanswering, code generation and many other tasks 24.The simplest and arguably deepest explanation for this history is that it isa consequence of the exponential growth of computational power and trainingdatasets, which continues to the present day. Given limited computing powerand data, the ability of the symbolic and pattern recognition approaches todirectly incorporate human understanding into a system is a significant advantage. On the other hand, given sufficiently large computing power and data,this advantage is nullified and may even become disadvantageous, as the humaneffort required to code the system becomes the limiting resource. This point,that the most significant advances in AI and computation more generally havecome from hardware improvements and replacing human engineering with datadriven methods, is forcefully made by Sutton in his bitter lesson essay 128.In 3, 4 and 8 we will discuss scaling laws and evidence for and against theidea that by continuing along the current path, training everlarger models oneverlarger datasets, we will achieve AGI artificial general intelligence, whateverthat means and the realms beyond.Up to now the symbolic and connectionist approaches have generally beenconsidered to be in tension.10 There is another point of view which considers them complementary, with a symbolic approach better suited for certainproblems for example logical reasoning and connectionist for others for example image recognition. Given this point of view one can seek a synthesis orneurosymbolic approach, advocated in many works 7, 47, 72.But are they in conflict at all? Another reconciliation is the hypothesis thatproblems which in the symbolic approach are solved using rules and algorithms,are also being solved that way by neural systems and in particular by LLMs.However, rather than the algorithms and rules being coded by humans, as theresult of its training procedure the LLM has somehow learned them, encodedin its networks in some as yet mysterious way. This vague hypothesis can besharpened in many ways, in part by proposing specific mechanisms by whichalgorithms and rules are encoded, in part by making general claims about thealgorithms which are being learned. We discuss these ideas in 7 and 8.10To better discuss this point one should refine the symbolicconnectionist dichotomy intomultiple axes system design versus learning from data meaningful rules versus uninterpretedmodels combinatorial versus differentiable optimization deterministic versus probabilistic.73Language modelsThroughout the history of linguistics, languages have been described in termsof rules rules of grammar, phonology, morphology, and so on, along with logical and other frameworks for describing meaning. This remains the case inChomskyan linguistics and in much of theoretical linguistics.By contrast, LLMs are statistical language models, meaning that they encodea probability distribution on strings of words, call this P w1 . . . wL, whichapproximates the distribution realized by a large body or corpus of text inthe language. The simplest example is the frequency or 1gram model definedby taking the words to be independently distributed, soP w1 . . .