Another approach is to first develop a detailed computationalmodel CM to perform a task without looking too much at the system understudy, and then look for evidence for or against the hypothesis that the systemunder study uses it. This approach also has a long history in neuroscience 91and ways to test such hypotheses have been much discussed. As an exampletiles on an 8 8 board, and each move results in flipping some opponent pieces to theplayers color. The main point for us is that the function from moves to board state is easilycomputable yet very nonlocal and nonlinear.38While this model shares the GPT architecture, it is not trained on any language data,just on Othello games.23of a research tactic which does not require opening the black box, one canconsider illusions which fool the system in some way. The response to thesewill often depend on contingent and nonoptimal aspects of the model, so onecan distinguish different models which solve the same task. A new class ofpredictions which becomes testable for LLMs is to look at performance as afunction of model size depth number of parameters. A particular CM mightrequire a certain model size or dataset properties in order to perform well. Andof course, one can open the black box by assuming a particular CM, one canmake predictions for what probe experiments should work.Simple tasks studied in this approach include modular addition 103 andlinear regression 2, where several CMs gradient descent, ridge regression andexact least squares were compared. Turning to language processing, a CM forparsing by transformer LLMs was developed in Zhou et al 143. While thisis too lengthy to explain in detail here, let us give the basic idea, startingfrom the PCFG framework discussed in the appendix. Rather than try torepresent a parse tree in terms of nodes and edges, it is represented by givingeach position i in the list of words a set of variables i,t,j, where t indexes anonterminal a left hand side of a rule and j is another position. If i,t,j isturned on, this means that a rule with t on the l.h.s. was used to generatethat part of the tree stretching from position i to position j. This can begeneralized to let i,t,j be the probability that a rule is used. These variablesand additional variables describing the rules used higher in the tree satisfysimple recursion relations the InsideOutside parsing algorithm 87.If therules have at most two symbols on the r.h.s.,39 these recursion relations arequadratic in the variables. By encoding the variables as components of theembedding, they can be implemented using attention.Naively, this model predicts that embedding dimension p must be very large,of order the number of nonterminals times the length of a sentence. Sincerealistic grammars for English have many hundreds of nonterminals, this seemsto contradict the good performance of transformers with p 1000. This problemis resolved by two observations, of which the first is that one can get fairly goodparsing with many fewer 20 nonterminals.