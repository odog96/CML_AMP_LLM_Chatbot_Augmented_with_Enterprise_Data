Fit without fear remarkable mathematical phenomena of deep learning through the prism of interpolation. arXiv2105.14368 cs, math, stat, May 2021. arXiv 2105.14368. URL httparxiv.org abs2105.14368. 14 Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Man dal. Reconciling modern machinelearning practice and the classical biasvariance tradeoff. Proceedings of the National Academy of Sci ences, 116321584915854, 2019. Publisher National Academy of eprint httpswww.pnas.orgcontent1163215849.full.pdf. Sciences URL httpswww.pnas.orgcontent1163215849, doi10.1073 pnas.1903070116. 15 Mikhail Belkin, Siyuan Ma, and Soumik Mandal. To understand deep learning we need to understand kernel learning. February 2018. URL httpsarxiv.orgabs1802.01396v3. 16 Emily M. Bender and Alexander Koller. Climbing towards NLU On mean ing, form, and understanding in the age of data. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 51855198, Online, July 2020. Association for Computational Lin guistics. URL httpsaclanthology.org2020.aclmain.463, doi 10.18653v12020.aclmain.463. 34 17 Yoshua Bengio. From system 1 deep learning to system 2 deep learning, December 2019. URL httpsslideslive.com38922304 fromsystem1deeplearningtosystem2deeplearning. 18 Yoshua Bengio, Rejean Ducharme, and Pascal Vincent. A neural proba bilistic language model. Advances in neural information processing sys tems, 13, 2000. 19 Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning, volume 4. Springer, 2006. 20 TaiDanae Bradley, John Terilla, and Yiannis Vlassopoulos. An enriched category theory of language from syntax to semantics. arXiv2106.07890 cs, math, June 2021. arXiv 2106.07890. URL httparxiv.orgabs 2106.07890. 21 Peter F Brown, Stephen A Della Pietra, Vincent J Della Pietra, Robert L Mercer, et al. The mathematics of statistical machine translation Pa rameter estimation. 1993. 22 Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christo pher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language Models are FewShot Learners. arXiv2005.14165 cs, June 2020. arXiv 2005.14165. URL httparxiv.orgabs2005. 14165. 23 Cameron B. Browne, Edward Powley, Daniel Whitehouse, Simon M. Lu cas, Peter I. Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis, and Simon Colton. A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games, 41143, 2012. 24 Sebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. Sparks of Artificial General Intelligence Early experi ments with GPT4, March 2023. URL httpsarxiv.orgabs2303. 12712v1. 25 Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt. Discovering Latent Knowledge in Language Models Without Supervision, December 2022. arXiv2212.03827 cs. URL httparxiv.orgabs2212.03827. 35 26 Yining Chen, Sorcha Gilroy, Andreas Maletti, Jonathan May, and Kevin Knight. Recurrent Neural Networks as Weighted Language Recognizers, March 2018. arXiv1711.05408 cs. URL httparxiv.orgabs1711. 05408, doi10.48550arXiv.1711.05408. 27 Ethan A. Chi, John Hewitt, and Christopher D. Manning. Finding Uni versal Grammatical Relations in Multilingual BERT. arXiv2005.04511 cs, May 2020. arXiv 2005.04511. URL httparxiv.orgabs2005.