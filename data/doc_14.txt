Thus physicists were motivated to build accelerators. These are not that expensive when they fit on a tabletop, but rapidly grow in size and cost. How large does an accelerator need to be? The right measure is not its size per se but rather the energy of the particles it can produce. The physics relating size and energy is not trivial due to effects such as synchrotron ra diation but can be worked out, so one can make a good prediction of energy reach. Still, as one increases energy, will one find a smooth extrapolation of what came before, or will one discover qualitatively new phenomena? In the golden age of accelerator physics the 50s70s much new physics was discov ered, mostly associated with new particles which are produced only above sharp energy thresholds. Currently the highest energy accelerator is the Large Hadron Collider at Cern, where the Higgs particle was discovered in 2012. While we are still waiting for further important discoveries, the potential for discovery is determined by measurable properties of the accelerator by energy and secon darily by intensity or luminosity which we can judge even in the absence of qualitative discoveries. In the analogy, perplexity is playing a similar role as an objective measure of language model performance defined independently of the more interesting qualitative behaviors which reflect intelligence. How far can one push this analogy? Could perplexity be as central to lan guage as energy is to physics? Eq. 3 has a fairly objective definition, so the idea is not completely crazy. But, not only was its relation to performance on actual tasks not predictable in advance, even after the fact clear thresholds or other signals for emergence of tasks have not yet been identified 133. Perhaps if there are universal thresholds, evidence for them could be seen in humans.25 More likely, additional variables the quality and nature of the training corpus, 24In 5 we explain how text can be thought of embedded in a high dimensional space. 25Thanks to Misha Tsodyks for this suggestion. 14 details of the tasks, etc. would need to be controlled to see them. This is another question probably better studied in simpler tasks using synthetic data. The final topic we discuss is the behavior of the objective function Eq. 3 as a function of training time.26 In almost all ML runs, such a plot shows long plateaus interspersed with steep drops. This has been interpreted in many ways, ranging from evidence about the nature of learning, to a simple consequence of randomness of eigenvalues of the Hessian of the loss function. A more recent observation is to compare training and testing accuracy on the same plot. In 9, 110 it was argued that these two metrics improve at two distinct stages of training. First, the model memorizes training examples. Later, it generalizes to the testing examples. This grokking phenomenon has been suggested as evidence for learning of circuits 103, an idea we discuss in 7.