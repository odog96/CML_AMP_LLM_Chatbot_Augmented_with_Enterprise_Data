If we hold one of these say P fixed and take the other say D to infinity, then a law of large numbers applies and L 1D. On the other hand, if we take one parameter very large and study the dependence on the other, nontrivial power law scaling can emerge. In principle one can get different exponents for D and P , suggesting the ansatz LP, D cid19P D cid34cid18 Pc P cid35D . Dc D 4 where L is test loss Eq. 3 computed in an optimally regularized model.23 This is a good fit to Figure 2. While in Figure 2 the two exponents appear to differ, there is not really convincing evidence that this is significant. Before working hard on this, one should ask if there is any way to control the many choices involved, so as to define universal exponents. One context in which this can be studied systematically is transfer learning, by distinguishing the dependence on the pretraining and fine tuning datasets 55. Another relevant and practical question is whether one can prune the dataset to improve the scaling. It is intuitively plausible and can be shown in examples that sets of data items are worth more if they are diverse than if they are similar. The challenge is to find simple ways to quantify this similarity in 126 many proposals are studied. 23Regularization is a standard technique in statistics and ML used to control overfitting by models with too many parameters. If one does not regularize one sees other phenomena such as double descent 14. For further discussion see 11, 13. 13 Scaling laws can arise in many ways, not specific to language models. One hypothesis is that the data lies on a low dimensional submanifold in a higher dimensional space.24 Both the number of parameters and the number of points required to fit this manifold go as the dimension d of the manifold, and this leads to P D 4d the precise coefficient 4 depends on assumptions about smoothness 8. A related hypothesis is that the spectral density of the data covariance falls off as a power law, and in 85 Eq. 4 is derived for a random feature model with this covariance. This hypothesis follows from the low dimensional hypothesis but it is more general, for example these authors argue that additional features derived from the data as in nonlinear models such as FFNs generally have the same spectrum as the original data. One can also try to relate Eq. 4 and corrections to it to hypotheses about how tasks are learned 98. What does the scaling of the information theoretic quantity Eq. 3 have to do with performance on tasks requiring intelligence? A priori, not much, but one way to motivate a focus on it is to draw an analogy with particle physics. In the 30s cosmic ray observations gave strong hints of new physics at higher energies, but the interesting events were too rare and uncontrolled to draw solid conclusions.