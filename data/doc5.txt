
How many requests per second can a deployed model handle?
Answer: The REST API is load balanced over replicas to run the model. Replicas run in containers and can be distributed to a number of hosts as needed based on the CPU, GPU and memory requirements to execute a prediction. The upper bound on performance will be determined by the load balancer proxy. With a model execution time of 20ms and 9 replicas we were able to achieve 100 requests/second. (reference)
AWS
Do we have competitive information on AWS Sagemaker? 
Answer: Yes, see Sagemaker recording and slides here. 

When choosing root size for ML nodes, what is recommended?
Answer: Default of 512GB is good. Don’t go below 256GB (absolute min). Slack link. 

How does ML Workspace backup and restore work?
Answer: General information is available in Baking up ML workspaces doc. Things to note:
UI is only available on AWS right now and requires additional prerequisites to be met. But on Azure the backup/restore can be done via CLI (ref). Azure backup doesn’t backup NFS.
Backup operation requires downtime on the ML workspace. 
Workspace can be restored to same or different CDP environment, as long as its in the same region and in the same cloud provider account.
Incremental backup is an implementation detail of how AWS Backup service works. EBS backups rely on disk snapshots, while EFS backups are done at filesystem leve. 
Restore operation always restores to the latest CML version, regardless of the backup version (ref).

Does CML support MLFlow experiments?
Answer: yes, this feature is Tech Preview (TP) right now, soon to be GA. Draft blog post on the topic. Also documentation for mlflow Experiments, in PDF format is available here. 

Does CML support MLFlow Model Registry?
Answer: yes, this feature is in Tech Preview (TP) behind entitlement ML_MODEL_REGISTRY. You will find documentation for this Preview feature is also available. Model registry has some API v2 CLI integration, but you cannot yet deploy a model from a model registry via CLI. Currently, a model cannot be deleted from the registry.

All registry operations are done by a machine user. That user needs permissions setup in Ranger.

There is a single model registry per environment. So, a model can be registered into the registry from one ML workspace, and deployed into a different ML workspace within the same environment. Cross-environment model deployment is in the works. 

Recording of SME call (pass: c!f?2$DA ) that includes current issues (as of March 1st, 2023) that were found by the field with model registry. 
Azure
What are NFS considerations on Azure and what do we recommend?
Answer: Cloudera recommends Azure Files NFS (Premium tier) be used for CML. While other NFS options are supported, Azure Files NFS is preferred due to lower cost (~50% cheaper storage cost) and ease of backup (for ML workspaces). The other NFS options are Azure NetApp Files or other 3rd party NFS provider that meets specified requirements. 

CML uses an NFS service to store project files. Project files can include user code, any libraries you install, and small data files. It is an anti-pattern to keep large datasets 1GB+ within projects. File share size of at least 100GB is recommended. Note that with NetApp 4TB is the minimum provisioned capacity. This is another reason why Azure Files NFS is preferred. 

If a customer is already using Azure NetApp or other 3prd party NFS, they can migrate to Azure Files NFS.

Do we have competitive information on Azure ML? 
Answer: Yes, see Azure ML competitive recording and slides here. 

What is the network layout of deploying CML on Azure?
Answer: See this network diagram created by Chris Van Dyke. 

Can we do private CML on Azure?
Answer: This is discussed in November 4, 2022 Enablement Call by Chris Van Dyke. Private clusters are now in Tech Preview (via entitlement) on Azure as well. 
GCP
When will CML be available on GCP?
Answer: Current target is FY25, but that’s not firm. If you have a customer who is asking for CML on GCP, please add them to a Vivun gap “CML on GCP”. There is also DSE-13765 for this.