This is real $$ savings for the customer not only from Cloudera perspective, but also from cloud provider compute savings. Whats the latest roadmap? When is X feature coming? Answer: PM updates roadmap for Public Cloud every month or two. Please check there first. If you dont see what you need, ask in #sme_ml and tag Peter Ableda. What are the different ML roles assigned to users? Answer: Start by reading User Roles doc. The environment roles (MLAdmin, MLUser, MLBusinessUser) work at the scope of environment. For example, MLUser would have access to all workspaces in a given environment. Workspace resource roles apply only at a single ML Workspace scope. MLAdmin role is needed to view Grafana dashboard. How to integrate VS Code with CML? Answer: You will need to download and configure cdswctl CLI first. Then, if you are not SSO user, supply an SSH key. If you are SSO, then you dont need to do that. Finally, use the Legacy API key when logging in with cdswctl. For more see Using VS Code with CML/CDSW. We also have public docs on this. How do GPUs help with CML? Answer: With GPUs you can get ~90% performance improvement in some cases, when using GPU in CML. Tensorflow is another framework that you can leverage on CML with GPUs. However, we do not support Spark workloads for CML. You can find some more context from this slack discussion. One note is that scaling up GPU from 0 to 1 instances can take up to 10 minutes all in itself. For Private Cloud perspective see here. Can CML be upgraded in-place? Answer: There is no CML upgrade at large, but rather each ML Workspace within CML data services can be upgraded. There are two types of upgrades available, including in-place upgrades. Always backup your ML Workspace before an upgrade. Is Iceberg supported? How do we use it with MLOps? Answer: Christina Sanchez has a great demo for using MLOps and Iceberg. You can watch the recording (passcode: %s7QiQff ) from a SME session where this was presented. Can a customer build a runtime from scratch? Answer: Yes, in fact our PBJ runtimes is open source now. This means that a customer can build their own special runtime that starts with a ubuntu (RHEL may be possible, but could be significant effort on customer side, we dont recommend it) image and they can package any version of various libraries that they need for their project. There is no Cloudera proprietary code in these runtime images. Note that custom PBJ runtimes do not support editors other than Cloudera workbench at this time. How to access private github repos to create projects? Answer: You will need to get a personal access token from Github and follow the procedure described in Cloudera community article How to import private repositories Github, gitlab. Once you use the token approach you can also easily git push to the remote repository from CML, without any additional setup required. Using