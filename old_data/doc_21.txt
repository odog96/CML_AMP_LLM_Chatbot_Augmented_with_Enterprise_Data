As in random matrix theory, this typically means varWi,j 1p, though there are refinements 140. One then sequences through the training corpus and performs a step of gradient descent of Eq. 3 for each batch of words here a group of 106 words. In each step, the parameters are modified as Lb 16 where Lb is Eq. 3 restricted to the batch, the conditional probability P comes out of Eq. 8 applied to the output of the transformer, and is a positive real number the learning rate hyperparameter, here around 104. The result of following this procedure on a dataset of natural language text,36 supplemented by many enhancements which are described in the literature and in the model source codes but which may be less important for conceptual understanding, is an LLM with the capabiliities we described. 7 Studying the internal workings The success of this procedure raises many questions. Some can be asked about more or less any ML model for example, questions about when and how optimization of the objective function Eq. 3 achieves good local minima value near the global minimum and models which generalize well, and the origin of scaling laws like Eq. 4. These are the subject of the general theory of machine learning, for which we refer to 19, 97, 116 and much other work. Other questions, and understanding the many striking abilities discussed earlier, sound more specific to LLMs. What would it mean to understand how ChatGPT writes poetry based on prompts, or solves physics word problems? At present this is by no means clear and it may be that entirely new concepts are needed to do this. Still, I share the belief that we can go very far towards understanding LLMs by building on previous work in computer science, ma chine learning and AI, and many other fields. There is a well established field of statistical physics and ML 97 which will surely contribute. Physics ideas are also very relevant for tasks with spatial symmetry, such as image genera tion 125 and recognition 35. The unexpected mathematical simplicity of the 36As always in ML it is important that the dataset be clean consistently tokenized, not having too much garbage text or repetitions, etc.. Many later LLMs also use programming language code in the dataset. Besides making code generation possible, it has been reported that this improves performance on natural language reasoning tasks. 21 transformer model means that mathematical insights could be valuable. We can also follow approaches used in neuroscience, psychology, and cognitive science. An evident observation is that the paradigm of neuroscience careful study of the microscopic workings of the system, following a reductionist philosophy is far more practical for ML models than it is for human brains, as the micro scopic workings are fully explicit. This is not to say that it is easy, as we still face the difficulty of extracting meaning from a system with billions of components and parameters. How could we do this for LLMs?