This is naturally possible for a computer programmed in assembly language, in which instructions are encoded in integers. To some extent it is also possible in Lisp, in which programs are encoded in a universal list data structure. As type systems and other programming language refinements are introduced, re flection becomes more difficult to provide, but it is necessary for systemslevel 30 programming and makes various standard tasks easier to implement. Since an LLM operates on language, reflection for an LLM is the ability to work with its internal model in linguistic terms. This is related to ML inter pretability, the ability to translate a model into understandable terms. In 7 we discussed interpretability of LLMs in terms of circuits and computational mod els, implicitly leaving these for a human to interpret and understand. One can imagine an interpretation engine which given a model, automatically produces a more interpretable description, in terms of circuits, rules, or even a description of the models functioning in natural language. Given such an interpretation engine, by applying it to an LLM and sending its output as an input to the LLM, we can implement a form of reflection. A basic human capability which corresponds to this process is the translation from procedural or other implicit forms of memory to linguistic, explicit mem ory. Very often, we learn by doing riding a bicycle, solving math problems, interacting socially. We then reflect on what we have learned in some uncon scious way and occasionally come up with verbal observations, summaries, in a word reflections. It is fascinating that combining the ideas we discussed brings us into contact with such topics. To conclude, and for what it is worth, out of the forty years I have followed AI, this is by far the most exciting period. I agree with those who think LLMs are a major milestone and believe the ideas behind them including the trans former architecture will remain important even in the light of future progress. The questions they raise are interesting and important enough that even as the specialists make remarkable progress we need not leave the field to them, but as scientists and thinkers we should engage and try to contribute. A Grammars and parsing Most readers will have encountered the idea of sentence diagram, which graph ically represents the decomposition of a sentence into clauses with a subject, verb and object, the assignment of adjectives and prepositional phrases to the nouns and verbs they modify, and so on. Formal versions of this concept are foundational in linguistics and computer science, and a short introduction or review is a good way to bring the general ideas we are discussing to life. A formal grammar can be given by a set of production rules which can be used to generate grammatical strings. A simple example is in Figure 3.