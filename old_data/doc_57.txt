13layers.3533Compare the logical implications A B and B A.34This term refers to model choices which are not learned through gradient descent.35Some of the attention layers in GPT3 are sparse.20 Number of heads H 96 the equality with D is a coincidence as far as Iknow.The total number of parameters is roughly 12Dp2.As mentioned earlier, all of these parameters, and the parameters of the embedding map Eq. 7, are determined as follows. One generally starts with random initial conditions, usually meaning that each parameter is drawn from anormal distribution with mean zero and variance chosen so that the linear mapshave expected norm independent of the hyperparameters. As in random matrixtheory, this typically means varWi,j 1p, though there are refinements 140.One then sequences through the training corpus and performs a step of gradientdescent of Eq. 3 for each batch of words here a group of 106 words. Ineach step, the parameters are modified as Lb16where Lb is Eq. 3 restricted to the batch, the conditional probability P comesout of Eq. 8 applied to the output of the transformer, and is a positive realnumber the learning rate hyperparameter, here around 104.The result of following this procedure on a dataset of natural language text,36supplemented by many enhancements which are described in the literature andin the model source codes but which may be less important for conceptualunderstanding, is an LLM with the capabiliities we described.7Studying the internal workingsThe success of this procedure raises many questions. Some can be asked aboutmore or less any ML model for example, questions about when and howoptimization of the objective function Eq. 3 achieves good local minimavalue near the global minimum and models which generalize well, and theorigin of scaling laws like Eq. 4. These are the subject of the general theory ofmachine learning, for which we refer to 19, 97, 116 and much other work.Other questions, and understanding the many striking abilities discussedearlier, sound more specific to LLMs. What would it mean to understand howChatGPT writes poetry based on prompts, or solves physics word problems?At present this is by no means clear and it may be that entirely new conceptsare needed to do this. Still, I share the belief that we can go very far towardsunderstanding LLMs by building on previous work in computer science, machine learning and AI, and many other fields. There is a well established fieldof statistical physics and ML 97 which will surely contribute. Physics ideasare also very relevant for tasks with spatial symmetry, such as image generation 125 and recognition 35. The unexpected mathematical simplicity of the36As always in ML it is important that the dataset be clean consistently tokenized, nothaving too much garbage text or repetitions, etc.. Many later LLMs also use programminglanguage code in the dataset. Besides making code generation possible, it has been reportedthat this improves performance on natural language reasoning tasks.21transformer model means that mathematical insights could be valuable.