It is intuitively plausible and canbe shown in examples that sets of data items are worth more if they are diversethan if they are similar. The challenge is to find simple ways to quantify thissimilarity in 126 many proposals are studied.23Regularization is a standard technique in statistics and ML used to control overfitting bymodels with too many parameters. If one does not regularize one sees other phenomena suchas double descent 14. For further discussion see 11, 13.13Scaling laws can arise in many ways, not specific to language models. Onehypothesis is that the data lies on a low dimensional submanifold in a higherdimensional space.24 Both the number of parameters and the number of pointsrequired to fit this manifold go as the dimension d of the manifold, and thisleads to P D 4d the precise coefficient 4 depends on assumptionsabout smoothness 8.A related hypothesis is that the spectral density of the data covariance fallsoff as a power law, and in 85 Eq. 4 is derived for a random feature model withthis covariance. This hypothesis follows from the low dimensional hypothesisbut it is more general, for example these authors argue that additional featuresderived from the data as in nonlinear models such as FFNs generally havethe same spectrum as the original data. One can also try to relate Eq. 4 andcorrections to it to hypotheses about how tasks are learned 98.What does the scaling of the information theoretic quantity Eq. 3 have todo with performance on tasks requiring intelligence? A priori, not much, butone way to motivate a focus on it is to draw an analogy with particle physics.In the 30s cosmic ray observations gave strong hints of new physics at higherenergies, but the interesting events were too rare and uncontrolled to draw solidconclusions. Thus physicists were motivated to build accelerators. These arenot that expensive when they fit on a tabletop, but rapidly grow in size andcost. How large does an accelerator need to be? The right measure is not itssize per se but rather the energy of the particles it can produce. The physicsrelating size and energy is not trivial due to effects such as synchrotron radiation but can be worked out, so one can make a good prediction of energyreach. Still, as one increases energy, will one find a smooth extrapolation ofwhat came before, or will one discover qualitatively new phenomena? In thegolden age of accelerator physics the 50s70s much new physics was discovered, mostly associated with new particles which are produced only above sharpenergy thresholds. Currently the highest energy accelerator is the Large HadronCollider at Cern, where the Higgs particle was discovered in 2012. While weare still waiting for further important discoveries, the potential for discovery isdetermined by measurable properties of the accelerator by energy and secondarily by intensity or luminosity which we can judge even in the absence ofqualitative discoveries.