From this point of view, a central question is the complexity class of circuits which can be realized by constant depth transformers, meaning that the number of layers does not grow with the window size. Roughly, this is the complexity class TC0 of constant depth circuits with threshold gates 28, 41, 95, 96. Of course in an autoregressive LLM one can repeat this operation to compute a sequence of words thus the circuit defines the transition function of a finite state machine FSM where the state is the window, and the LLM has learned to simulate this FSM. If a natural algorithm to perform a task is in a more difficult complexity class than the FSM can handle, this is a reason to think the task cannot be learned by this type of LLM. Conversely, one might conjecture that any task for which there is an algorithm in this class can be learned, at least in the limit of an infinite amount of training data. What about the lenses of pure mathematics, theoretical physics and allied fields? Besides my own personal interest in them, these fields have made sub stantial contributions to statistics and machine learning, especially the interface between statistical physics and machine learning is a vibrant field of research 71, 97. Spin glass theory made a very deep impact, starting with the Hopfield model and developing into a farreaching theory of optimization landscapes and complexity. Random matrix theory is central to high dimensional statistics 63 and in many approaches to understanding deep learning 116. Mathematical approaches to language such as 20, 34, 86, 89 can reveal new structure and provide deeper understanding. Another reason to think pure mathematics and theoretical physics have more to contribute is that neural networks, transformers, and many of the models of neuroscience, are formulated in terms of real variables and continuous mathe matics. By contrast, computer science is largely based on discrete mathematics, appropriate for some but not all questions. Perhaps word embeddings have im portant geometric properties, or perhaps the dynamics of gradient descent are best understood through the intuitions of continuous mathematics and physics. Arguments such as those in 7 which reduce neural networks to digital circuits, even if they do explain their functioning, may not be adequate to explain how they are learned. Having at least mentioned some of the many points of view, let me combine these insights and speculate a bit on where this is going. Let me focus on three capabilities which seem lacking in current LLMs planning, confidence 28 judgments, and reflection. Planning, solving problems whose solution requires choosing a series of ac tions andor the consideration of future actions by other agents, is one of the core problems of AI. Making plans generally requires search, and in general search is hard assuming P NP. A familiar example is a chess program, which searches through a game tree to judge the longer term value of a candi date move by hypothesizing possible future moves.