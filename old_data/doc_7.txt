In 3, 4 and 8 we will discuss scaling laws and evidence for and against the idea that by continuing along the current path, training everlarger models on everlarger datasets, we will achieve AGI artificial general intelligence, whatever that means and the realms beyond. Up to now the symbolic and connectionist approaches have generally been considered to be in tension.10 There is another point of view which consid ers them complementary, with a symbolic approach better suited for certain problems for example logical reasoning and connectionist for others for ex ample image recognition. Given this point of view one can seek a synthesis or neurosymbolic approach, advocated in many works 7, 47, 72. But are they in conflict at all? Another reconciliation is the hypothesis that problems which in the symbolic approach are solved using rules and algorithms, are also being solved that way by neural systems and in particular by LLMs. However, rather than the algorithms and rules being coded by humans, as the result of its training procedure the LLM has somehow learned them, encoded in its networks in some as yet mysterious way. This vague hypothesis can be sharpened in many ways, in part by proposing specific mechanisms by which algorithms and rules are encoded, in part by making general claims about the algorithms which are being learned. We discuss these ideas in 7 and 8. 10To better discuss this point one should refine the symbolicconnectionist dichotomy into multiple axes system design versus learning from data meaningful rules versus uninterpreted models combinatorial versus differentiable optimization deterministic versus probabilistic. 7 3 Language models Throughout the history of linguistics, languages have been described in terms of rules rules of grammar, phonology, morphology, and so on, along with log ical and other frameworks for describing meaning. This remains the case in Chomskyan linguistics and in much of theoretical linguistics. By contrast, LLMs are statistical language models, meaning that they encode a probability distribution on strings of words, call this P w1 . . . wL, which approximates the distribution realized by a large body or corpus of text in the language. The simplest example is the frequency or 1gram model defined by taking the words to be independently distributed, so P w1 . . . wL L cid89 i1 P wi P w number of occurrences of w in the corpus total number of words in the corpus . 1 Of course, this model captures very little of the structure of language, which involves dependencies between the word choices. LLMs are generative models,11 by which we will mean that there is a practi cal method for sampling from the distribution. To explain this, consider a word prediction task in which some words in a string are given the input and others left blank the output. Given a probability distribution P w1 . . . wL, there is a corresponding conditional probability distribution for the output given the input.