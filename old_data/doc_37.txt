Inductive Biases for Deep Learn arXiv2011.15091 cs, ing of HigherLevel Cognition, August 2022. stat. URL httparxiv.orgabs2011.15091, doi10.48550arXiv. 2011.15091. 51 Andrey Gromov. Grokking modular arithmetic, January 2023. URL httparxiv.orgabs2301. arXiv2301.02679 condmat. 02679, doi10.48550arXiv.2301.02679. 52 Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and Dino Pedreschi. A Survey of Methods for Explain ing Black Box Models. ACM Computing Surveys, 515142, September 2019. URL httpsdl.acm.orgdoi10.11453236009, doi10.1145 3236009. 53 Thilo Hagendorff. Machine Psychology Investigating Emergent Capabil ities and Behavior in Large Language Models Using Psychological Meth ods, April 2023. arXiv2303.13988 cs. URL httparxiv.orgabs 2303.13988, doi10.48550arXiv.2303.13988. 54 Michael Hahn and Navin Goyal. A Theory of Emergent InContext Learning as Implicit Structure Induction, March 2023. arXiv2303.07971 cs. URL httparxiv.orgabs2303.07971, doi10.48550arXiv. 2303.07971. 55 Danny Hernandez, Jared Kaplan, Tom Henighan, and Sam McCan dlish. arXiv2102.01293 cs. URL httparxiv.orgabs2102.01293, doi10.48550arXiv. 2102.01293. Scaling Laws for Transfer, February 2021. 56 John Hewitt and Christopher D Manning. A Structural Probe for Finding Syntax in Word Representations. page 10, 2019. 57 Sepp Hochreiter and Jurgen Schmidhuber. Long shortterm memory. Neu ral computation, 9817351780, 1997. 58 Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. Training ComputeOptimal Large Language Models, March 2022. arXiv2203.15556 cs. URL httparxiv.org abs2203.15556, doi10.48550arXiv.2203.15556. 38 59 Benjamin Hoover, Yuchen Liang, Bao Pham, Rameswar Panda, Hendrik Strobelt, Duen Horng Chau, Mohammed J. Zaki, and Dmitry Krotov. Energy Transformer, February 2023. arXiv2302.07253 condmat, qbio, stat. URL httparxiv.orgabs2302.07253, doi10.48550arXiv. 2302.07253. 60 FengHsiung Hsu. Behind Deep Blue Building the computer that defeated the world chess champion. Princeton University Press, 2002. 61 Myeongjun Jang and Thomas Lukasiewicz. Consistency Analysis of Chat GPT, March 2023. arXiv2303.06273 cs. URL httparxiv.orgabs 2303.06273, doi10.48550arXiv.2303.06273. 62 Albert Q. Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothee Lacroix, Yuhuai Wu, and Guillaume Lample. Draft, Sketch, and Prove Guiding Formal Theorem Provers with Informal Proofs, November 2022. arXiv2210.12283 cs. URL httparxiv.org abs2210.12283, doi10.48550arXiv.2210.12283. 63 Iain M. Johnstone. High Dimensional Statistical Inference and Ran dom Matrices, November 2006. URL httpsarxiv.orgabsmath 0611589v1. 64 Dan Jurafsky and James H Martin. Speech and language processing, 2009. 65 Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield Dodds, Nova Das Sarma, Eli TranJohnson, Scott Johnston, Sheer ElShowk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, and Jared Kaplan. Language Mod els Mostly Know What They Know, July 2022. arXiv2207.05221 cs. URL httparxiv.orgabs2207.05221. 66 Daniel Kahneman. Fast and slow thinking. Allen Lane and Penguin Books, New York, 2011. 67 Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B.