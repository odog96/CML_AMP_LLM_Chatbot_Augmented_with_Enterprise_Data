URL httpswww.semanticscholar.orgpaperLanguageModelsareUnsupervisedMultitaskLearnersRadfordWu9405cc0d6169988371b2755e573cc28650d14dfe.114 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, SharanNarang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the Limits of Transfer Learning with a Unified TexttoText Transformer. arXiv1910.10683 cs, stat, July 2020. arXiv 1910.10683. URLhttparxiv.orgabs1910.10683.115 Hubert Ramsauer, Bernhard Schafl, Johannes Lehner, Philipp Seidl,Michael Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner,Milena Pavlovic, Geir Kjetil Sandve, Victor Greiff, David Kreil, MichaelKopp, Gunter Klambauer, Johannes Brandstetter, and Sepp Hochreiter.Hopfield Networks is All You Need, April 2021. arXiv2008.02217 cs,stat. URL httparxiv.orgabs2008.02217, doi10.48550arXiv.2008.02217.116 Daniel A. Roberts, Sho Yaida, and Boris Hanin. The Principles of DeepLearning Theory. arXiv2106.10165 hepth, stat, August 2021. arXiv2106.10165. URL httparxiv.orgabs2106.10165.117 Frank Rosenblatt. The perceptron a probabilistic model for informationstorage and organization in the brain. Psychological review, 656386,1958.118 David E. Rumelhart, Geoffrey E. Hinton, and James L. McClelland. Ageneral framework for parallel distributed processing. 1986.119 Stuart J Russell. Artificial intelligence a modern approach. Pearson Education, Inc., 2010.120 Rylan Schaeffer, Brando Miranda, and Oluwasanmi Koyejo. Are emergentabilities of large language models a mirage? ArXiv, abs2304.15004, 2023.121 Terrence J Sejnowski. The deep learning revolution. MIT press, 2018.122 Claude E Shannon. Xxii. programming a computer for playing chess. TheLondon, Edinburgh, and Dublin Philosophical Magazine and Journal ofScience, 41314256275, 1950.123 Hava T Siegelmann and Eduardo D Sontag. On the computational powerof neural nets. In Proceedings of the fifth annual workshop on Computational learning theory, pages 440449, 1992.124 Brian Cantwell Smith. Procedural reflection in programming languagesvolume i. 1982.44125 Jascha SohlDickstein, Eric Weiss, Niru Maheswaranathan, and SuryaGanguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International Conference on Machine Learning, pages 22562265.PMLR, 2015. arXiv1503.03585.126 Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, andAri S. Morcos. Beyond neural scaling laws beating power law scaling viadata pruning, June 2022. Number arXiv2206.14486 arXiv2206.14486cs, stat. URL httparxiv.orgabs2206.14486, doi10.48550arXiv.2206.14486.127 Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, et al. Beyond theImitation Game Quantifying and extrapolating the capabilities of language models. Technical Report arXiv2206.04615, arXiv, June 2022.arXiv2206.04615 cs, stat type article. URL httparxiv.orgabs2206.04615.128 Richard Sutton.The bitterincompleteideas.netIncIdeasBitterLesson.html.lesson, 2019.URL httpwww.129 Christian Szegedy. A promising path towards autoformalization and general artificial intelligence. In International Conference on Intelligent Computer Mathematics, 2020.130 Shubham Toshniwal, Sam Wiseman, Karen Livescu, and Kevin Gimpel. Chess as a Testbed for Language Model State Tracking, May2022. arXiv2102.13249 cs. URL httparxiv.orgabs2102.13249,doi10.48550arXiv.2102.13249.131 Richard E. Turner.An Introduction to Transformers, July 2023.arXiv2304.10557 cs. URL httparxiv.orgabs2304.10557, doi10.48550arXiv.2304.10557.132 Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, LlionJones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. June 2017. arXiv 1706.03762. URL httpsarxiv.orgabs1706.03762.133 Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, DonaldMetzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang,Jeff Dean, and William Fedus. Emergent Abilities of Large LanguageModels. 2022. Publisher arXiv Version Number 2. URL httpsarxiv.orgabs2206.07682, doi10.48550ARXIV.2206.07682.134 Gail Weiss, Yoav Goldberg, and Eran Yahav. On the Practical Computational Power of Finite Precision RNNs for Language Recognition, May2018. arXiv1805.04908 cs, stat. URL httparxiv.orgabs1805.04908, doi10.48550arXiv.1805.04908.45135 Sean Welleck, Jiacheng Liu, Ronan Le Bras, Hannaneh Hajishirzi, YejinChoi, and Kyunghyun Cho. NaturalProofs Mathematical Theorem Proving in Natural Language.